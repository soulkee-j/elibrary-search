import streamlit as st
import requests
from lxml import html
import re
from urllib.parse import quote

st.set_page_config(page_title="í†µí•© ì „ìë„ì„œê´€ ê²€ìƒ‰", page_icon="ğŸ“š")

# ê¸°ë³¸ ë„ì„œê´€ (ì„±ë‚¨, ê²½ê¸°ëŒ€, ìš©ì¸, ìˆ˜ì›, ê³ ì–‘, ê°•ë‚¨)
libraries = [
    {"name": "ì„±ë‚¨ì‹œ ì „ìë„ì„œê´€", "url": "https://vodbook.snlib.go.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8", "type": "standard"},
    {"name": "ê²½ê¸°ëŒ€í•™êµ", "url": "https://ebook.kyonggi.ac.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8", "type": "standard"},
    {"name": "ìš©ì¸ì‹œ ì „ìì±…ë„ì„œê´€", "url": "https://ebook.yongin.go.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8", "type": "standard"},
    {"name": "ìˆ˜ì›ì‹œ ì „ìë„ì„œê´€", "url": "https://ebook.suwonlib.go.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8", "type": "standard"},
    {"name": "ê³ ì–‘ì‹œ ë„ì„œê´€ì„¼í„°", "url": "https://ebook.goyanglib.or.kr/elibrary-front/search/searchList.ink", "key_param": "schTxt", "xpath": '//*[@id="container"]/div/div[4]/p/strong[2]/text()', "encoding": "utf-8", "type": "standard"},
    {"name": "ê°•ë‚¨êµ¬ ì „ìë„ì„œê´€", "url": "https://ebook.gangnam.go.kr/elibbook/book_info.asp", "key_param": "strSearch", "xpath": '//*[@id="container"]/div[1]/div[2]/div[1]/div/div[2]/div[1]/div[1]/div/strong/text()', "encoding": "euc-kr", "type": "gangnam"}
]

def search_libraries(book_name):
    results = []
    progress_bar = st.progress(0)
    
    # ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ê¸° ìœ„í•œ í—¤ë” ì„¤ì • (ì¤‘ìš”!)
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}

    # 1. ì¼ë°˜ ë„ì„œê´€ ê²€ìƒ‰
    for i, lib in enumerate(libraries):
        progress_bar.progress((i + 1) / (len(libraries) + 4))
        try:
            query = quote(book_name.encode(lib["encoding"]))
            search_url = f"{lib['url']}?{lib['key_param']}={query}"
            if lib["type"] == "standard": search_url += "&schClst=ctts%2Cautr&schDvsn=001"
            elif lib["type"] == "gangnam": search_url += "&search=title"

            resp = requests.get(search_url, headers=headers, timeout=5)
            tree = html.fromstring(resp.content)
            nodes = tree.xpath(lib["xpath"])
            count = int(re.findall(r'\d+', "".join(nodes))[0]) if nodes and re.findall(r'\d+', "".join(nodes)) else 0
            results.append({"ë„ì„œê´€": lib['name'], "ê²°ê³¼": f"[{count}ê¶Œ ë°œê²¬]({search_url})" if count > 0 else "ì—†ìŒ"})
        except:
            results.append({"ë„ì„œê´€": lib['name'], "ê²°ê³¼": "í™•ì¸ë¶ˆê°€"})

    # 2. ì„œìš¸ë„ì„œê´€ (API ë°©ì‹)
    try:
        seoul_api = f"https://elib.seoul.go.kr/api/contents/search?keyword={quote(book_name)}&t=EB"
        seoul_resp = requests.get(seoul_api, headers=headers, timeout=5).json()
        s_count = seoul_resp.get('data', {}).get('totalCount', 0)
        s_link = f"https://elib.seoul.go.kr/contents/search/content?t=EB&k={quote(book_name)}"
        results.append({"ë„ì„œê´€": "ì„œìš¸ë„ì„œê´€", "ê²°ê³¼": f"[{s_count}ê¶Œ ë°œê²¬]({s_link})" if s_count > 0 else "ì—†ìŒ"})
    except:
        results.append({"ë„ì„œê´€": "ì„œìš¸ë„ì„œê´€", "ê²°ê³¼": "í™•ì¸ë¶ˆê°€"})

    # 3. ì„œì´ˆêµ¬ (API ë°©ì‹)
    try:
        sc_api = f"https://e-book.seocholib.or.kr/api/contents/search?keyword={quote(book_name)}"
        sc_resp = requests.get(sc_api, headers=headers, timeout=5).json()
        eb_count = sc_resp.get('data', {}).get('totalCount', 0)
        
        sub_api = f"{sc_api}&contentType=SUBS"
        sub_resp = requests.get(sub_api, headers=headers, timeout=5).json()
        sub_count = sub_resp.get('data', {}).get('totalCount', 0)
        
        sc_link = f"https://e-book.seocholib.or.kr/search?keyword={quote(book_name)}"
        results.append({"ë„ì„œê´€": "ì„œì´ˆêµ¬(ì „ìì±…)", "ê²°ê³¼": f"[{eb_count}ê¶Œ ë°œê²¬]({sc_link})" if eb_count > 0 else "ì—†ìŒ"})
        results.append({"ë„ì„œê´€": "ì„œì´ˆêµ¬(êµ¬ë…í˜•)", "ê²°ê³¼": f"[{sub_count}ê¶Œ ë°œê²¬]({sc_link}&contentType=SUBS)" if sub_count > 0 else "ì—†ìŒ"})
    except:
        results.append({"ë„ì„œê´€": "ì„œì´ˆêµ¬ ë„ì„œê´€", "ê²°ê³¼": "í™•ì¸ë¶ˆê°€"})

    # 4. ë¶€ì²œì‹œ (ë³´ì•ˆ í¬íŠ¸ ëŒ€ì‘)
    try:
        bc_url = f"https://ebook.bcl.go.kr:444/elibrary-front/search/searchList.ink?schTxt={quote(book_name)}&schClst=ctts%2Cautr&schDvsn=001"
        bc_resp = requests.get(bc_url, headers=headers, timeout=5, verify=False) # SSL ê²€ì¦ ë¬´ì‹œ
        tree = html.fromstring(bc_resp.content)
        bc_nodes = tree.xpath('//*[@id="container"]/div/div[4]/p/strong[2]/text()')
        bc_count = int(re.findall(r'\d+', "".join(bc_nodes))[0]) if bc_nodes else 0
        results.append({"ë„ì„œê´€": "ë¶€ì²œì‹œë¦½ë„ì„œê´€", "ê²°ê³¼": f"[{bc_count}ê¶Œ ë°œê²¬]({bc_url})" if bc_count > 0 else "ì—†ìŒ"})
    except:
        results.append({"ë„ì„œê´€": "ë¶€ì²œì‹œë¦½ë„ì„œê´€", "ê²°ê³¼": "í™•ì¸ë¶ˆê°€"})

    progress_bar.empty()
    return results

# í™”ë©´ êµ¬ì„± (Alfred ì—°ë™ í¬í•¨)
st.title("ğŸ“š í†µí•© ì „ìë„ì„œê´€ ê²€ìƒ‰")
st.markdown("---")

query_params = st.query_params
url_keyword = query_params.get("search", "")

keyword = st.text_input("ì±… ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”", value=url_keyword, placeholder="ì˜ˆ: í–‰ë³µì˜ ê¸°ì›", key="search_input")

if keyword:
    with st.spinner(f"'{keyword}' ê²€ìƒ‰ ì¤‘..."):
        res = search_libraries(keyword)
        col1, col2 = st.columns([2, 1])
        col1.write("**ë„ì„œê´€ ì´ë¦„**")
        col2.write("**ì†Œì¥ í˜„í™© (í´ë¦­ ì‹œ ì´ë™)**")
        st.divider()
        for item in res:
            c1, c2 = st.columns([2, 1])
            c1.write(item["ë„ì„œê´€"])
            c2.markdown(item["ê²°ê³¼"])
